{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopMentions(series:pd.Series, times:int) -> Counter:\n",
    "    listOfMentions = series.tolist()\n",
    "    flattenListOfMentions = [j for mention in listOfMentions for j in mention]\n",
    "    lowerCase = [mention.lower() for mention in flattenListOfMentions]\n",
    "    print(\"Mentions: \", len(lowerCase))\n",
    "    print(lowerCase)\n",
    "    return Counter(lowerCase).most_common(times)\n",
    "\n",
    "def plotTopMentions(mostCommon:Counter, title:str):\n",
    "    bar = plt.bar(*zip(*mostCommon))\n",
    "    plt.bar_label(bar)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(title)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from json-File.\n",
    "\n",
    "with open('../Final.json') as f:\n",
    "    d = json.load(f)\n",
    "df = json_normalize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_conversation_ids = pd.read_excel('../bellingcat_grouped_conversation_inclu_warPeriod_Final_lang_mode_thread.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using tweets original tweeted from bellingcat or replies from bellingcat on they own tweets (threads)\n",
    "only_en_conversation_ids = used_conversation_ids[used_conversation_ids['lang'] == 'en']['conversation_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df['conversation_id'].isin(only_en_conversation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of threads, that are contain urls/photos/media\n",
    "\n",
    "test = df_en.groupby('conversation_id').count()\n",
    "\n",
    "# url photo media\n",
    "url_photo_media = np.zeros(len(test))\n",
    "for index, value in test[['entities.urls', 'attachments.media']].items():\n",
    "    for id, item in enumerate(value):\n",
    "        if(item > 0):\n",
    "            url_photo_media[id] = 1\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{(sum(url_photo_media)/len(test))*100}% contains urls/photos/media in the threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The complete dataset contain {len(df_en)} tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract which tweet is retweet and which is no retweet\n",
    "\n",
    "is_no_retweeted = []\n",
    "for index, value in df_en['referenced_tweets'].items():\n",
    "    if(type(value) == list and value[0].get('type') == \"retweeted\"):\n",
    "        is_no_retweeted.append(False)\n",
    "    else:\n",
    "        is_no_retweeted.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every tweet is used exepct of retweets and tweets who are not in english language\n",
    "# so replys and quoted tweets are included in the analysis\n",
    "df_en_no_RT =  df_en[is_no_retweeted]\n",
    "df_en_no_RT.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_en_no_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract which tweet is retweet and which is no retweet\n",
    "tweet_is_thread = []\n",
    "for index, value in df_en_no_RT['in_reply_to_user_id'].items():\n",
    "    if(math.isnan(float(value))):\n",
    "        tweet_is_thread.append(True)\n",
    "    elif(value == \"2315512764\"):\n",
    "        tweet_is_thread.append(True)\n",
    "    else:\n",
    "        tweet_is_thread.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_no_RT_only_thread = df_en_no_RT[tweet_is_thread]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_en_no_RT_only_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the amount of photos, animated gifs and videos from the dataset\n",
    "amount_photos = 0\n",
    "amount_animated_gifs = 0\n",
    "amount_videos = 0\n",
    "for index, value in df_en_no_RT_only_thread[~df_en_no_RT_only_thread['attachments.media'].isnull()]['attachments.media'].items(): \n",
    "    for media in value:\n",
    "        if media.get('type') == \"photo\":\n",
    "            amount_photos = amount_photos + 1\n",
    "        if media.get('type') == \"animated_gif\":\n",
    "            amount_animated_gifs = amount_animated_gifs + 1\n",
    "        if media.get('type') == \"video\":\n",
    "            amount_videos = amount_videos + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the amount of urls -> Mentions are urls as well\n",
    "amount_urls = 0\n",
    "for index, value in df_en_no_RT_only_thread[~df_en_no_RT_only_thread['entities.urls'].isnull()]['entities.urls'].items(): \n",
    "    amount_urls = amount_urls + len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tweets = {}\n",
    "count_tweets['urls'] = amount_urls\n",
    "count_tweets['photos'] = amount_photos\n",
    "count_tweets['animated_gifs'] = amount_animated_gifs\n",
    "count_tweets['videos'] = amount_videos\n",
    "count_tweets = {k: v for k, v in sorted(count_tweets.items(), key=lambda item: item[1], reverse=True)}\n",
    "bar = plt.bar(count_tweets.keys(), count_tweets.values())\n",
    "plt.title('Amount of Tweets with Media')\n",
    "plt.bar_label(bar)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mentions from the tweets and the username of the mentioned account\n",
    "mentions = []\n",
    "for index, value in df_en_no_RT_only_thread[~df_en_no_RT_only_thread['entities.mentions'].isnull()]['entities.mentions'].items():\n",
    "    for mention in value:\n",
    "        mentions.append(mention.get('username'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_amount = 10\n",
    "most_common_mentions = Counter(mentions).most_common(most_common_amount)\n",
    "plotTopMentions(most_common_mentions, f'TOP_{most_common_amount}_MENTIONS -> total {len(mentions)} mentions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the hashtags from the tweets\n",
    "hashtags = []\n",
    "for index, value in df_en_no_RT_only_thread[~df_en_no_RT_only_thread['entities.hashtags'].isnull()]['entities.hashtags'].items():\n",
    "    for hashtag in value:\n",
    "        hashtags.append(hashtag.get('tag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_hashtags = Counter(hashtags).most_common(most_common_amount)\n",
    "plotTopMentions(most_common_hashtags, f'TOP_{most_common_amount}_HASHTAGS -> total {len(hashtags)} hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting data for plotting in R with ggplot2\n",
    "pd.DataFrame(data=most_common_mentions, columns=['hashtag', 'count']).to_csv('../plotting_R/most_common_mentions.csv')\n",
    "pd.DataFrame(data=most_common_hashtags, columns=['hashtag', 'count']).to_csv('../plotting_R/most_common_hashtags.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92c6157a433797f433e80c5b8542eb47b20ef3ee248b9e28a2229743b12ebd1c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
