{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d96a51e",
   "metadata": {},
   "source": [
    "## Regression analysis for Bellingcat threads\n",
    "\n",
    "This code estimates estimates a regression model for different characteristics of Bellingcat's threads on engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64c53b",
   "metadata": {},
   "source": [
    "Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import tkinter\n",
    "import datetime\n",
    "from datetime import datetime as datetime_1\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define paths\n",
    "path_data = \"../../DataSources/\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2806e72",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1523f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load thread data\n",
    "df_thread = pd.read_excel(path_data + \"bellingcat_grouped_conversation_inclu_warPeriod_Final_lang_mode_thread_mention.xlsx\", index_col=0)\n",
    "\n",
    "# Load follower data\n",
    "df_followers = pd.read_excel(path_data + \"Followers_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f29bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess thread data\n",
    "df_thread['year'] = df_thread.date.dt.year\n",
    "df_thread['month'] = df_thread.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess follower data\n",
    "df_followers = df_followers[[\"Date\",\"followers\"]].groupby([pd.Grouper(freq=\"M\",key=\"Date\")])[\"followers\"].max().reset_index()\n",
    "df_followers['year'] = df_followers.Date.dt.year\n",
    "df_followers['month'] = df_followers.Date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efeee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join thread and follower data\n",
    "df_thread = df_thread.merge(df_followers, how=\"left\", on=[\"year\",\"month\"]).drop(columns=['month', 'year', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210e727",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Only keep english threads\n",
    "df_thread = df_thread[df_thread['lang']==\"en\"]\n",
    "# Drop observations before observation period\n",
    "df_thread = df_thread[df_thread['date']>=datetime.datetime(year=2014,month=7,day=1)]\n",
    "# Drop observations without followers\n",
    "df_thread.dropna(subset=['followers'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text for sentiment analysis\n",
    "def preprocess_tweets(text):\n",
    "    fo = open(\"Stopwords-en.txt\",\"+r\")\n",
    "    stop_words = list(fo.read().split(','))\n",
    "    translation={39:None}\n",
    "    processed_tweet = text\n",
    "    processed_tweet=' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    processed_tweet = \" \".join(word for word in processed_tweet.split() if word not in str(stop_words).translate(translation))\n",
    "    return(processed_tweet)\n",
    "\n",
    "df_thread['processed_text'] = df_thread['text'].apply(lambda x: preprocess_tweets(x.lower()))\n",
    "\n",
    "# Clean Rows where Processed Tweet is Empty (e.g. because if it is only a Link)\n",
    "def EmptyRows(dataset): \n",
    "    nan_value = float(\"NaN\")\n",
    "    dataset.replace(\"\",nan_value, inplace=True)\n",
    "    dataset.dropna(subset = ['processed_text'], inplace= True)\n",
    "    \n",
    "EmptyRows(df_thread)\n",
    "\n",
    "# Compute sentiment of thread\n",
    "df_thread[\"polarity\"] = df_thread[\"processed_text\"].apply(lambda x: analyzer.polarity_scores(x))\n",
    "\n",
    "# Group sentiment (positive vs. negative vs. neutral)\n",
    "def sentimentPredict(sentiment):\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif sentiment['compound'] <= -0.05: \n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df_thread[\"sentiment\"] = df_thread[\"polarity\"].apply(lambda x: sentimentPredict(x))\n",
    "\n",
    "# Unstack polarity\n",
    "df_thread = pd.concat([df_thread.drop([\"polarity\"], axis=1), df_thread[\"polarity\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "# Set sentiment and polarity to NA for empty strings (e.g, because they only include a URL, Mention, etc.)\n",
    "#df_thread.loc[df_thread[\"processed_text\"] == \"\", \"compound\"] = np.nan\n",
    "#df_thread.loc[df_thread[\"processed_text\"] == \"\", \"sentiment\"] = np.nan\n",
    "\n",
    "# Create numeric sentiment variable\n",
    "df_thread.loc[df_thread[\"sentiment\"] == \"positive\", \"sentiment_num\"] = 1\n",
    "df_thread.loc[df_thread[\"sentiment\"] == \"negative\", \"sentiment_num\"] = -1\n",
    "df_thread.loc[df_thread[\"sentiment\"] == \"neutral\", \"sentiment_num\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute engagement\n",
    "df_thread[\"engagement\"] = df_thread[[\"likes\", \"replies\", \"quotes\", \"retweets\"]].sum(axis=1)\n",
    "# Normalize engagement by follower and tweet count\n",
    "df_thread[\"norm_engagement\"] = df_thread[\"engagement\"]/(df_thread[\"followers\"] * df_thread[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement by sentiment\n",
    "df_thread.groupby(\"sentiment\")[\"norm_engagement\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a236d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thread[[\"likes\", \"replies\", \"quotes\", \"retweets\", \"engagement\", \"followers\", \"count\", \"norm_engagement\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thread\n",
    "for cols in df_thread.columns:\n",
    "    print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa461feb",
   "metadata": {},
   "source": [
    "Regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariates\n",
    "covariates = [ \"urls\", \"media_photo\", \"media_videos\", \"hashtags\", \"mentions\", \"compound\"]\n",
    "\n",
    "# Drop missing data \n",
    "all_variables = []\n",
    "all_variables.extend(covariates + [\"norm_engagement\"])\n",
    "df_thread = df_thread.dropna(axis=0, subset=all_variables)\n",
    "\n",
    "# Compute log engagement\n",
    "df_thread[\"log_engagement\"] = np.log(df_thread[\"norm_engagement\"], where=df_thread[\"norm_engagement\"] != 0)\n",
    "# Set log_engagement to min(norm_engagement) for values == 0\n",
    "min_engagement = np.min(df_thread.loc[df_thread[\"norm_engagement\"] != 0, \"norm_engagement\"])\n",
    "df_thread.loc[df_thread[\"norm_engagement\"] == 0, \"log_engagement\"] = np.log(min_engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa13a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of engagement\n",
    "quantiles = np.quantile(df_thread['log_engagement'], np.linspace(0.1, 0.9, 8))\n",
    "sns.histplot(df_thread['log_engagement'], kde=True,  bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfa4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize independent variables\n",
    "scaler = StandardScaler().fit(df_thread[covariates])\n",
    "X = scaler.transform(df_thread[covariates])\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model (log_engagement)\n",
    "model_lm = sm.OLS(endog=df_thread[\"log_engagement\"], exog=sm.add_constant(df_thread[covariates]))\n",
    "results = model_lm.fit(cov_type=\"HC3\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4094ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model (norm_engagement)\n",
    "model_lm = sm.OLS(endog=df_thread[\"norm_engagement\"], exog=sm.add_constant(df_thread[covariates]))\n",
    "results = model_lm.fit(cov_type=\"HC3\")\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
