{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#import aggregation as aggregation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px\n",
    "\n",
    "#Sentimentanalysis - Dictionary Approach\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "import nest_asyncio\n",
    "import re\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#Date manipulation\n",
    "import time\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import dateutil.relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('../../DataSources/bellingcat_grouped_conversation_inclu_warPeriod_Final_lang_mode_thread_mention.xlsx')\n",
    "# Sentiment Analysis only about \"normal Tweets & Threads\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sentimentanalyse with vader regarding Bellingcats conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#analyse only english -> that`s also a limitation because\n",
    "#e.g. russian replys are not taken into account if the are written in Cyrillic\n",
    "df1 = df1[df1.lang == 'en']\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_tweets(text):\n",
    "    fo = open(\"Stopwords-en.txt\",\"+r\")\n",
    "    stop_words = list(fo.read().split(','))\n",
    "    translation={39:None}\n",
    "    processed_tweet = text\n",
    "    processed_tweet=' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    processed_tweet = \" \".join(word for word in processed_tweet.split() if word not in str(stop_words).translate(translation))\n",
    "    return(processed_tweet)\n",
    "\n",
    "df1['Processed Tweet'] = df1['text'].apply(lambda x: preprocess_tweets(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#second opportunity of data cleaning (I am using now the first one)\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Clean Rows where Processed Tweet is Empty (e.g. because if it is only a Link)\n",
    "def EmptyRows(dataset): \n",
    "    nan_value = float(\"NaN\")\n",
    "    dataset.replace(\"\",nan_value, inplace=True)\n",
    "    dataset.dropna(subset = ['Processed Tweet'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Split date into year,month day date-columns\n",
    "def SplitDate(dataset):\n",
    "    dataset['year']=pd.to_datetime(dataset['date']).dt.strftime('%Y')\n",
    "    dataset['month']=pd.to_datetime(dataset['date']).dt.strftime('%m')\n",
    "    dataset['day']=pd.to_datetime(dataset['date']).dt.strftime('%A')\n",
    "    dataset['year-month']=pd.to_datetime(dataset['date']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EmptyRows(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1['polarity'] = df1['Processed Tweet'].apply(lambda x: analyzer.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sentimentPredict(sentiment):\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif sentiment['compound'] <= -0.05: \n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df1['sentiment'] =df1['polarity'].apply(lambda x: sentimentPredict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for creating columns for each dic item in polarity\n",
    "df1 = pd.concat([df1.drop(['polarity'], axis=1), df1['polarity'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_sentiment = df1[[\"media_photo_Binary\",'media_videos_Binary','urls_Binary','hashtags_Binary',\"compound\",\"quantiles\"]]\n",
    "print(df_sentiment.head())\n",
    "df_sentiment = df_sentiment[(df_sentiment[\"quantiles\"]==\"Q1\")|(df_sentiment[\"quantiles\"]==\"Q4\")]\n",
    "df_sentiment['quantiles'] = df_sentiment['quantiles'].replace('Q1', 0)\n",
    "df_sentiment['quantiles'] = df_sentiment['quantiles'].replace('Q4', 1)\n",
    "print(df_sentiment.head())\n",
    "df_sentiment.to_csv(\"../../DataSources/Dataset_Graphs/RQ2_Content_Engagement/engagement_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.title('Classification of Bot Replys into sentiment categories',fontsize=15)\n",
    "plt.ylabel('Percentage [%]',fontsize=18)\n",
    "ax = (df1.sentiment.value_counts()/len(df1)*100).plot(kind=\"bar\", rot=0,color=['#04407F','#0656AC','#0A73E1'])\n",
    "ax.set_yticks(np.arange(0, 110, 10))\n",
    "plt.grid(color='#95a5a6', linestyle='-.', linewidth=1, axis='y', alpha=0.7)\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(np.arange(0, 110, 10)*len(df1)/100)\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.2f}%'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SplitDate(df1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grouped = df1.groupby(by='year')['sentiment'].value_counts()\n",
    "#grouped_class=df3.groupby(by='year')['type_of_tweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unstacked = grouped.unstack(level=1)\n",
    "#grouped_class = grouped.unstack(level=1)\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unstacked.plot.bar(figsize=(18,12),title=\"Absolute distribution of Sentiments in Sentiment Conversations during ukraine war\")\n",
    "plt.xticks(rotation=45)\n",
    "#grouped_class.plot.bar(figsize=(18,12))ÃŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cross_tab_prop2 = pd.crosstab(index=df1['year'],columns=df1['sentiment'], normalize='index')\n",
    "cross_tab_prop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cross_tab_prop2.plot(kind='bar',stacked=True,figsize=(18,12))\n",
    "plt.legend(loc=\"upper left\", ncol=2)\n",
    "plt.title('Relative distribution of Sentiments in Bellingcats Conversations',fontsize=15)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for n, x in enumerate([*cross_tab_prop2.index.values]):\n",
    "    for (proportion, y_loc) in zip(cross_tab_prop2.loc[x],\n",
    "                                   cross_tab_prop2.loc[x].cumsum()):\n",
    "                \n",
    "        plt.text(x=n - 0.17,\n",
    "                 y=y_loc,\n",
    "                 s=f'{np.round(proportion * 100, 1)}%', \n",
    "                 color=\"black\",\n",
    "                 fontsize=20,\n",
    "                 fontweight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5100bb95e858b9e941e8e80aa0f5067cd86ed5041e3728ba4b0f2d37cb5109fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
