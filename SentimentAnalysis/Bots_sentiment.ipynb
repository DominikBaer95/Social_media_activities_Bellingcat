{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import aggregation as aggregation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px\n",
    "from plotnine import *\n",
    "#from ggplot import *\n",
    "\n",
    "#Sentimentanalysis - Dictionary Approach\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "import nest_asyncio\n",
    "import re\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#Date manipulation\n",
    "import time\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import dateutil.relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "botthreshold = 0.5\n",
    "\n",
    "df1 = pd.read_csv('../../DataSources/BotReplies.csv') # Bot-Replies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sentimentanalyse with vader regarding Bellingcats Bot-Replys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#analyse only english replys -> that`s also a limitation because \n",
    "#e.g. russian replys are not tatken into account if the are written in Cyrillic\n",
    "df1 = df1[df1.lang == 'en']\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_tweets(text):\n",
    "    \n",
    "    fo = open(\"Stopwords-en.txt\",\"+r\")\n",
    "    stop_words = list(fo.read().split(','))\n",
    "    translation={39:None}\n",
    "    processed_tweet = text\n",
    "    processed_tweet=' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    processed_tweet = \" \".join(word for word in processed_tweet.split() if word not in str(stop_words).translate(translation))\n",
    "    return(processed_tweet)\n",
    "\n",
    "df1['Processed Tweet'] = df1['text'].apply(lambda x: preprocess_tweets(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#second opportunity of data cleaning (I am using now the first one\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Clean Rows where Processed Tweet is Empty (e.g. because Reply is only a Link)\n",
    "def EmptyRows(dataset): \n",
    "    nan_value = float(\"NaN\")\n",
    "    dataset.replace(\"\",nan_value, inplace=True)\n",
    "    dataset.dropna(subset = ['Processed Tweet'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def SplitDate(dataset): \n",
    "    dataset['year']=pd.to_datetime(dataset['date']).dt.strftime('%Y')\n",
    "    dataset['month']=pd.to_datetime(dataset['date']).dt.strftime('%m')\n",
    "    dataset['day']=pd.to_datetime(dataset['date']).dt.strftime('%A')\n",
    "    dataset['year-month']=pd.to_datetime(dataset['date']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EmptyRows(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1['polarity'] = df1['Processed Tweet'].apply(lambda x: analyzer.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sentimentPredict(sentiment):\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif sentiment['compound'] <= -0.05: \n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df1['sentiment'] =df1['polarity'].apply(lambda x: sentimentPredict(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for creating columns for eacht dic item in polarity\n",
    "df1 = pd.concat([df1.drop(['polarity'], axis=1), df1['polarity'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.title('Classification of Bot Replys into sentiment categories',fontsize=15)\n",
    "plt.ylabel('Percentage [%]',fontsize=18)\n",
    "ax = (df1.sentiment.value_counts()/len(df1)*100).plot(kind=\"bar\", rot=0,color=['#04407F','#0656AC','#0A73E1'])\n",
    "ax.set_yticks(np.arange(0, 110, 10))\n",
    "plt.grid(color='#95a5a6', linestyle='-.', linewidth=1, axis='y', alpha=0.7)\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(np.arange(0, 110, 10)*len(df1)/100)\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.2f}%'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
